{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Example of using LLM-based information retrieval for recommendation task"
      ],
      "metadata": {
        "id": "FwZCzOrBiPLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run in google colaboratory"
      ],
      "metadata": {
        "id": "mA01PTxtiZ7O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5XSKV1GUITL",
        "outputId": "c46ad42e-4e72-4a4f-cf16-c9a7f9450cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "repo_path = '/content/drive/MyDrive/Colab Notebooks/thesis_work/llm-for-rec'\n",
        "sys.path.append(repo_path)"
      ],
      "metadata": {
        "id": "aTCMg9alUxbp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(os.path.join(repo_path, \"tasks\", \"information_retrieval\"))"
      ],
      "metadata": {
        "id": "4CbOB7sClLv1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install requirements"
      ],
      "metadata": {
        "id": "u9hGFxfMgZ0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r '{repo_path}/requirements/requirements.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uap-swa3TDb2",
        "outputId": "57dbe525-9f56-4a46-e1d0-9015235f2d92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add config"
      ],
      "metadata": {
        "id": "TQAMxZgdgeD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "config_dict = {'csv_args': {'delimiter': '\\t'},\n",
        " 'source_column': 'item_id:token',\n",
        " 'search_kwargs': {'k': 20, 'score_threshold': 0.5},\n",
        "  'data_path': os.path.join(repo_path, \"datasets\"),\n",
        " 'load_col': {'inter': ['user_id', 'item_id', 'rating', 'timestamp'],\n",
        "  'item': ['item_id', 'title']},\n",
        " 'text_col': 'title',\n",
        " 'MAX_ITEM_LIST_LENGTH': 10,\n",
        "  'eval_args': {'split': {'LS': 'valid_and_test'},\n",
        "  'order': 'TO',\n",
        "  'mode': 'full'},\n",
        " 'repeatable': True,\n",
        " 'loss_type': 'CE',\n",
        " 'train_batch_size': 100,\n",
        " 'eval_batch_size': 8,\n",
        " 'valid_metric': 'NDCG@10',\n",
        " 'metrics': ['Recall', 'NDCG'],\n",
        " 'topk': [1, 5, 10, 20],\n",
        " 'train_neg_sample_args': None\n",
        "}"
      ],
      "metadata": {
        "id": "F2D78xcfX1Do"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get dataset and config"
      ],
      "metadata": {
        "id": "nGcsWPfigiCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llm4rec.tasks import RecBoleRetrievalRecommender\n",
        "from llm4rec.dataset import RecboleSeqDataset\n",
        "from llm4rec.trainer import PipelineTrainer\n",
        "from recbole.data.utils import data_preparation\n",
        "from recbole.config import Config\n",
        "from recbole.model.abstract_recommender import AbstractRecommender\n",
        "import os\n",
        "import torch\n",
        "\n",
        "model_cls = RecBoleRetrievalRecommender\n",
        "dataset_name = 'amazon-books'\n",
        "\n",
        "config = Config(model=model_cls, dataset=dataset_name,\n",
        "            config_dict=config_dict)\n",
        "\n",
        "dataset = RecboleSeqDataset(config)\n",
        "_, _, test_data = data_preparation(config, dataset)"
      ],
      "metadata": {
        "id": "MJwYQflWYQ5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case 1: open source information retrieval using HuggingFace Sentence Transformers model"
      ],
      "metadata": {
        "id": "7EKCEve2gooO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_cls(config=config,\n",
        "                embeddings=None,\n",
        "                items_info_path=os.path.join(config['data_path'], f\"{config['dataset']}.item\"),\n",
        "                source_column=config['source_column'],\n",
        "                csv_args=config['csv_args'],\n",
        "                text_splitter_args=dict(chunk_size=500, chunk_overlap=0),\n",
        "                search_type=\"similarity\",\n",
        "                search_kwargs=config['search_kwargs'],\n",
        "                emb_model_name=\"all-MiniLM-L6-v2\",\n",
        "                emb_model_kwargs={\"device\":\"gpu\" if torch.cuda.is_availabe() else \"cpu\"},\n",
        "                dataset=dataset)\n",
        "\n",
        "trainer = PipelineTrainer(config, model)\n",
        "test_result = trainer.evaluate(test_data, show_progress=config['show_progress'])"
      ],
      "metadata": {
        "id": "VAiBrj60UODj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result"
      ],
      "metadata": {
        "id": "KrD9Aem6fkZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case 2: OpenAI information retrieval using OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "pVrs8rQjgypv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "path_to_openai_env = os.path.join(repo_path, \"openai.env\")\n",
        "load_dotenv(path_to_openai_env)\n",
        "\n",
        "openai_api_key = os.environ.get(\"API_KEY\")\n",
        "embeddings_model = OpenAIEmbeddings(\n",
        "            openai_api_key=openai_api_key, model=\"text-embedding-ada-002\"\n",
        "        )\n",
        "model = model_cls(config=config,\n",
        "                embeddings=embeddings_model,\n",
        "                items_info_path=os.path.join(config['data_path'], f\"{config['dataset']}.item\"),\n",
        "                source_column=config['source_column'],\n",
        "                csv_args=config['csv_args'],\n",
        "                text_splitter_args=dict(chunk_size=500, chunk_overlap=0),\n",
        "                search_type=\"similarity\",\n",
        "                search_kwargs=config['search_kwargs'],\n",
        "                emb_model_name=\"\",\n",
        "                emb_model_kwargs=None,\n",
        "                dataset=dataset)\n",
        "\n",
        "trainer = PipelineTrainer(config, model)\n",
        "test_result = trainer.evaluate(test_data, show_progress=config['show_progress'])"
      ],
      "metadata": {
        "id": "eizxloxQfxP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0sEp2Nveb1h",
        "outputId": "770a483f-5d24-4621-b228-a6ee225f8d32"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('recall@1', 0.0),\n",
              "             ('recall@5', 0.0),\n",
              "             ('recall@10', 0.0),\n",
              "             ('recall@20', 0.0),\n",
              "             ('ndcg@1', 0.0),\n",
              "             ('ndcg@5', 0.0),\n",
              "             ('ndcg@10', 0.0),\n",
              "             ('ndcg@20', 0.0)])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ]
}