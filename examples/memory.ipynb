{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO/M2L4eK92QQZIC2cSHcyo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-5nRfBBIeMLl","executionInfo":{"status":"ok","timestamp":1715707154520,"user_tz":-180,"elapsed":2104,"user":{"displayName":"Ирина Мальцева","userId":"12751035672140619453"}},"outputId":"56862b87-e9b6-4f78-e072-2c60c3d95096"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys\n","import os\n","\n","repo_path = '/content/drive/MyDrive/Colab Notebooks/thesis_work/llm-for-rec'\n","sys.path.append(repo_path)"],"metadata":{"id":"M2MzWfKVsxh_","executionInfo":{"status":"ok","timestamp":1715707154520,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ирина Мальцева","userId":"12751035672140619453"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install -q -r '{repo_path}/requirements/requirements.txt'"],"metadata":{"id":"EmviU9ZtpxdX","executionInfo":{"status":"ok","timestamp":1715707167592,"user_tz":-180,"elapsed":13075,"user":{"displayName":"Ирина Мальцева","userId":"12751035672140619453"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","config_dict = {\n","    \"csv_args\": {\"delimiter\": \"\\t\"},\n","    \"source_column\": \"item_id:token\",\n","    \"search_kwargs\": {\"k\": 20},\n","    \"data_path\": os.path.join(repo_path, \"datasets\"),\n","    \"load_col\": {\n","        \"inter\": [\"user_id\", \"item_id\", \"rating\", \"timestamp\"],\n","        \"item\": [\"item_id\", \"movie_title\"],\n","        \"user\": [\"user_id\", \"age\", \"gender\"]\n","    },\n","    \"text_col\": [\"movie_title\", \"release_year\", \"class\"],\n","    \"MAX_ITEM_LIST_LENGTH\": 10,\n","    \"eval_args\": {\"split\": {\"LS\": \"valid_and_test\"}, \"order\": \"TO\", \"mode\": \"full\"},\n","    \"repeatable\": True,\n","    \"loss_type\": \"CE\",\n","    \"train_batch_size\": 100,\n","    \"eval_batch_size\": 8,\n","    \"valid_metric\": \"NDCG@10\",\n","    \"metrics\": [\"Recall\", \"NDCG\"],\n","    \"topk\": [1, 5, 20],\n","    \"train_neg_sample_args\": None,\n","}"],"metadata":{"id":"TqabeFV3ZnPI","executionInfo":{"status":"ok","timestamp":1715707167593,"user_tz":-180,"elapsed":5,"user":{"displayName":"Ирина Мальцева","userId":"12751035672140619453"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from llm4rec.pipelines import RecBolePipelineRecommender\n","from llm4rec.dataset import RecboleSeqDataset\n","from llm4rec.trainer import PipelineTrainer\n","from recbole.data.utils import data_preparation\n","from recbole.config import Config\n","from recbole.model.abstract_recommender import AbstractRecommender\n","import os\n","import torch\n","\n","model_cls = RecBolePipelineRecommender\n","dataset_name = 'ml-100k'\n","\n","config = Config(model=model_cls, dataset=dataset_name,\n","            config_dict=config_dict)\n","\n","dataset = RecboleSeqDataset(config)\n","train_data, _, eval_data = data_preparation(config, dataset)"],"metadata":{"id":"UX58lXXDZqnG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715707183979,"user_tz":-180,"elapsed":16390,"user":{"displayName":"Ирина Мальцева","userId":"12751035672140619453"}},"outputId":"13e303bb-db6f-45f4-c884-a0c77c4246a7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-1100401b-7b29-4ec9-9748-981e910cee0b.json] will not be used in RecBole\n"]}]},{"cell_type":"code","source":["from dotenv import load_dotenv\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain import HuggingFaceHub\n","import torch\n","\n","embedding_size = 384\n","embedding_fn = HuggingFaceEmbeddings(\n","                model_name=\"all-MiniLM-L6-v2\", model_kwargs={\"device\":\"cuda:0\" if torch.cuda.is_available() else \"cpu\"})\n","\n","path_to_openai_env = os.path.join(repo_path, \"huggingface.env\")\n","load_dotenv(path_to_openai_env)\n","\n","llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", model_kwargs={\"temperature\":0.1, \"max_new_tokens\":512,\n","                                                                                  \"return_full_text\":False})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpkvH-Oyu5th","executionInfo":{"status":"ok","timestamp":1715707188256,"user_tz":-180,"elapsed":4291,"user":{"displayName":"Ирина Мальцева","userId":"12751035672140619453"}},"outputId":"440eb8e6-b834-4777-a996-8096bf3df3cc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. Use HuggingFaceEndpoint instead.\n","  warn_deprecated(\n"]}]},{"cell_type":"markdown","source":["## Init memory"],"metadata":{"id":"wrXQFGnQ-JoM"}},{"cell_type":"code","source":["from llm4rec.memory import ItemMemory\n","\n","item_memory = ItemMemory()\n","for item_id in dataset.item_id_token:\n","    item_memory.update(item_id, dataset.item_token2text(item_id))"],"metadata":{"id":"Sf3mL979pXaM","executionInfo":{"status":"ok","timestamp":1715707196260,"user_tz":-180,"elapsed":308,"user":{"displayName":"Ирина Мальцева","userId":"12751035672140619453"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from llm4rec.memory import UserMemory\n","\n","user_memory = UserMemory(user_attributes=dataset.user_token2text,\n","                         short_term_limit=20, llm=llm,\n","                         embeddings=embedding_fn,\n","                         item_memory=item_memory,\n","                         emb_size=embedding_size)"],"metadata":{"id":"A0QWsoIPpOsL","executionInfo":{"status":"ok","timestamp":1715707197478,"user_tz":-180,"elapsed":2,"user":{"displayName":"Ирина Мальцева","userId":"12751035672140619453"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","history_matrix, _, history_lens = train_data.dataset.history_item_matrix()\n","inter_matrix = train_data.dataset.inter_matrix('csr', value_field='rating')\n","user_id_mapping = lambda user_ids: train_data.dataset.id2token('user_id', user_ids)\n","item_id_mapping =  lambda item_ids: train_data.dataset.id2token('item_id', item_ids)\n","min_rating = 1\n","max_rating = 5\n","num_inter = 25\n","\n","n_users = 5\n","\n","for user_id in range(1, n_users):\n","    user_history = history_matrix[user_id][:history_lens[user_id]].tolist()\n","    ratings = inter_matrix[user_id, :].toarray() * (max_rating-min_rating) + min_rating\n","    ratings = ratings.astype('int')[0]\n","\n","    for item, rating in zip(user_history, ratings):\n","        user_memory.update(str(user_id), {'rating':rating, 'item_id':str(item)})"],"metadata":{"id":"JxS1mw-bcu_q","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc0a27f9-6360-4d84-a7fa-b6b163f0c2b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:Max value of user's history interaction records has reached 43.612596553773024% of the total.\n"]}]},{"cell_type":"code","source":["user_memory.short_term_memory.memory_store"],"metadata":{"id":"SEyh_CI6shye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_memory.long_term_memory.memory_store"],"metadata":{"id":"xFUtG-vl5mBW"},"execution_count":null,"outputs":[]}]}